{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4yf-k6aaFVg"
      },
      "source": [
        "### Type Casting\n",
        "- Convert user_input variable into integer and print the value and type\n",
        "- Convert sales amount to string and print this message `Total Sales : $1250.75`\n",
        "- Write a Python program that takes the string '123$', remove the dollar sign, and convert the remaining value to an integer\n",
        "\n",
        "- Given the tracking number 'JOR-2023-5678', write a Python program that uses string slicing to extract the shipment year and the unique ID, then print them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "uMQ4t52KaFrN"
      },
      "outputs": [],
      "source": [
        "user_input = \"123.45\"\n",
        "sales_amount = 1250.75\n",
        "price = '123$'\n",
        "tracking_number = \"JOR-2023-5678\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Q1 Solution "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "123 <class 'float'>\n",
            "1250.75 <class 'str'>\n",
            "123 <class 'int'>\n",
            "2023 5678\n"
          ]
        }
      ],
      "source": [
        "#1\n",
        "user_input = float(str(user_input))\n",
        "print(int(user_input),type(user_input))\n",
        "#2\n",
        "sales_amount = str(sales_amount)\n",
        "print(sales_amount, type(sales_amount))\n",
        "#3\n",
        "price = int(price.replace(\"$\", \"\"))\n",
        "print(price, type(price))\n",
        "#4\n",
        "tracking_number = tracking_number.split(\"-\")\n",
        "year = tracking_number[1]\n",
        "id = tracking_number[2]\n",
        "print(year, id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNMUKK9KcoMG"
      },
      "source": [
        "###  Arithmetic Operators\n",
        "Calculate these metrics :\n",
        "1. **unprocessed records** : how many records are still left to process?\n",
        "2. **completion rate (%)** : what percentage of the total file has been processed?\n",
        "3. **file size in GB** : convert the file size from megabytes to gigabytes (1024 MB is 1 GB)\n",
        "4. **number of full batches**: how many complete batches can you form from the total records, where each batch must be **exactly the full size?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "Q0ZhxZuGa336"
      },
      "outputs": [],
      "source": [
        "record_count = 25750       # Total number of records in the file\n",
        "batch_size = 500           # Each batch can process this many records\n",
        "processed_records = 750    # Number of records already processed\n",
        "file_size_mb = 2048        # File size in megabytes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Q2 Solution "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "oo8EwVQSgUXc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unprocessed Records: 25000\n",
            "Completion Rate: 2.912621359223301\n",
            "File Size in GB: 2.0\n",
            "Number of Complete Batches: 51\n"
          ]
        }
      ],
      "source": [
        "#1. unprocessed records\n",
        "unprocessed_records = record_count - processed_records\n",
        "print(\"Unprocessed Records:\", unprocessed_records)\n",
        "\n",
        "# 2. Completion Rate (%)\n",
        "completion_rate = (processed_records / record_count) * 100\n",
        "print(\"Completion Rate:\" , completion_rate)\n",
        "\n",
        "# 3. File Size in GB\n",
        "file_size_gb = file_size_mb / 1024 \n",
        "print(f\"File Size in GB: {file_size_gb}\")\n",
        "\n",
        "# 4. Number of Complete Batches\n",
        "complete_batches = record_count // batch_size #Ø¨Ø§Ù‚ÙŠ Ø§Ù„Ù‚Ø³Ù…Ø© \n",
        "print(\"Number of Complete Batches:\", complete_batches)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdYk9xTagcaN"
      },
      "source": [
        "### Comparison Operators\n",
        "Write boolean expressions to check if:\n",
        "1. Check if there is enough data to process\n",
        "  - ðŸ’¡ does the actual number of rows meet or exceed the minimum required?\n",
        "2. Check if the error rate is acceptable\n",
        "  - ðŸ’¡ is the current error rate within the allowed maximum?\n",
        "3. Check if processing finished within the time limit\n",
        "  - ðŸ’¡ compare the processing time against the maximum allowed\n",
        "4. Check if all of the above conditions are true\n",
        "  - ðŸ’¡use the and operator to combine multiple Boolean expressions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "fSHpJ9Ffi4dU"
      },
      "outputs": [],
      "source": [
        "min_required_rows = 1000\n",
        "actual_rows = 1250\n",
        "max_error_rate = 0.05\n",
        "current_error_rate = 0.03\n",
        "processing_time = 120\n",
        "max_time_allowed = 300"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Q3 Solution "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjfXhCmkiMJV",
        "outputId": "87ecab7f-9283-4b6b-b04d-08718ea013be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enough data to process: True\n",
            "Error rate acceptable: True\n",
            "Finished within time limit: True\n",
            "All conditions met: True\n"
          ]
        }
      ],
      "source": [
        "# 1. Enough data?\n",
        "has_enough_data = actual_rows >= min_required_rows\n",
        "print(\"Enough data to process:\", has_enough_data)\n",
        "# 2. Error rate acceptable?\n",
        "error_rate_ok = current_error_rate <= max_error_rate\n",
        "print(\"Error rate acceptable:\", error_rate_ok)\n",
        "# 3. Finished in time?\n",
        "finished_in_time = processing_time <= max_time_allowed\n",
        "print(\"Finished within time limit:\", finished_in_time)\n",
        "# 4. All conditions met?\n",
        "all_conditions_met = has_enough_data and error_rate_ok and finished_in_time\n",
        "print(\"All conditions met:\", all_conditions_met)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c98SRPCepJcv"
      },
      "source": [
        "### String manipulations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQdaxvS5pXP3",
        "outputId": "ee25c10a-349b-438a-a5c0-b93aeca4f3c4"
      },
      "outputs": [],
      "source": [
        "messy_data = \"    DaTa ANALYTICS @ sitech  \""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Q4 Solution "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DaTa ANALYTICS @ sitech\n",
            "Data Analytics At Sitech\n"
          ]
        }
      ],
      "source": [
        "\n",
        "## 1. remove extra spaces at the beginning and end of the string\n",
        "messy_data_1 = messy_data.strip()\n",
        "print(messy_data_1)\n",
        "\n",
        "## 2. replace the @ symbol with the word \"at\"\n",
        "messy_data_2 = messy_data_1.replace(\"@\", \"at\")\n",
        "## 3. change the string so that each word starts with an uppercase letter\n",
        "messy_data_3 = messy_data_2.title()\n",
        "print(messy_data_3)\n",
        "\n",
        "## Expected output : Data Analytics At Sitech"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NlxmDYCt6rK"
      },
      "source": [
        "### Lists - Sequential Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [],
      "source": [
        "customer_ids = [1001, 1002, 1003, 1004]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Q5 Soultion "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "PE0kuentt7DQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total customers 4\n",
            "Updated customer IDs: 5\n",
            "First customer: 1001\n",
            "Last customer: 1007\n",
            "Last 3 customers: [1005, 1006, 1007]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 1. print the number of customer ids in above list\n",
        "print(\"Total customers\", len(customer_ids))\n",
        "\n",
        "# 2. Adding new customer 1005 to above list\n",
        "customer_ids.append(1005)\n",
        "print(\"Updated customer IDs:\", len(customer_ids))\n",
        "# 3. add multiple new customer IDs [1006, 1007] at once to the existing list\n",
        "customer_ids.extend([1006, 1007]) #different from append\n",
        "\n",
        "\n",
        "## Accessing data\n",
        "\n",
        "# 1. first customer\n",
        "print(f\"First customer: {customer_ids[0]}\")\n",
        "\n",
        "# 2. last_customer\n",
        "print(f\"Last customer: {customer_ids[-1]}\")\n",
        "\n",
        "# last 3 customers\n",
        "print(f\"Last 3 customers: {customer_ids[-3:]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [],
      "source": [
        "sales_data = [100, 250, 175, 300, 225]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "bat"
        }
      },
      "source": [
        "Q6 Soultion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XucAFgswuWG1",
        "outputId": "b6a97cd0-6903-4a34-b578-2c3b6c4a37db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Sales 1050\n",
            "Highest Sale 300\n",
            "Average Sale 210.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 1. What is the total of all sales?\n",
        "print(\"Total Sales\" , sum(sales_data))\n",
        "\n",
        "# 2. What is the highest sale recorded?\n",
        "print(\"Highest Sale\", max(sales_data))\n",
        "\n",
        "# 3. What is the average sale value?\n",
        "print(\"Average Sale\", sum(sales_data) / len(sales_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "XLigoAcVsEYn"
      },
      "outputs": [],
      "source": [
        "## Parse and Process CSV-like Strings\n",
        "full_record = \"Ahmed,Mohammed, Data Analyst, 3, Data Dept\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Q7 Soultion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First Name: Ahmed\n",
            "Years of Experience:  3\n",
            "Full Name: Ahmed Mohammed\n"
          ]
        }
      ],
      "source": [
        "## 1. Split the string into separate values using the comma as a separator? (Use a method that turns a string into a list based on a delimiter.)\n",
        "\n",
        "NewFullRecord = full_record.split(\",\")\n",
        "## 2. After splitting, how do you get just the first name?\n",
        "\n",
        "first_name = NewFullRecord[0]\n",
        "print(\"First Name:\", first_name)\n",
        "## 3. Get the number of years of experience as an integer?\n",
        "\n",
        "years_of_experience = (NewFullRecord[3])\n",
        "print(\"Years of Experience:\", years_of_experience)\n",
        "\n",
        "## 4. Join the first and last name with a space instead of a comma?\n",
        "full_name = \" \".join(NewFullRecord[:2]) #takes just string before the comma (:\n",
        "print(\"Full Name:\", full_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8NY-3xAvmFd"
      },
      "source": [
        "### Tuples - Immutable Records"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gJ2zvyVvo-T"
      },
      "source": [
        "You are given a tuple representing a database connection configuration, can you extract the individual values (the host, port, and database name) from the tuple and store them in separate variables?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "jvLN8KzBv9Bj"
      },
      "outputs": [],
      "source": [
        "db_config = (\"localhost\", 5432, \"analytics_db\")\n",
        "\n",
        "## separate variables need to hold the host, port and database_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Q8 soultion "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Host: localhost\n",
            "Port: 5432\n",
            "Database Name: analytics_db\n"
          ]
        }
      ],
      "source": [
        "db_config_host, db_config_port, db_config_dbname = db_config # everything after the comma is assigned to the variable\n",
        "print(\"Host:\", db_config_host)\n",
        "print(\"Port:\", db_config_port)\n",
        "print(\"Database Name:\", db_config_dbname)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKVyrQPxxqEq"
      },
      "source": [
        "### Dictionaries - Key-Value Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "mnU037kTxuiH"
      },
      "outputs": [],
      "source": [
        "customer_sales_record = {\n",
        "    \"id\": 1001,\n",
        "    \"name\": \"Ahmed Mohammed\",\n",
        "    \"email\": \"ahmed@email.com\",\n",
        "    \"purchases\": 15,\n",
        "    \"total_spent\": 1250.75\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Spent: 1250.75\n",
            "Last Login: 2025-08-07\n",
            "record after update {'id': 1001, 'name': 'Ahmed Mohammed', 'email': 'ahmed@email.com', 'purchases': 15, 'total_spent': 1250.75, 'last_login': '2025-08-07'}\n",
            "Updated Purchases: 16\n"
          ]
        }
      ],
      "source": [
        "\n",
        "## 1. get the customer's name from the dictionary\n",
        "\n",
        "customer_name = customer_sales_record.get(\"name\")\n",
        "\n",
        "\n",
        "## 2. safely access \"total_spent\" or return 0 if it doesnt exist.\n",
        "\n",
        "if customer_sales_record.get(\"total_spent\") is None:\n",
        "    customer_sales_record[\"total_spent\"] = 0\n",
        "else:\n",
        "    costmost = customer_sales_record.get(\"total_spent\")\n",
        "print(\"Total Spent:\", costmost)\n",
        "\n",
        "## 3. add a new key \"last_login\" with the value \"2025-08-07\"\n",
        "customer_sales_record[\"last_login\"] = \"2025-08-07\"\n",
        "print(\"Last Login:\", customer_sales_record[\"last_login\"])\n",
        "print(\"record after update\",customer_sales_record)\n",
        "## 4. increase the customers purchase count by 1\n",
        "customer_sales_record[\"purchases\"] += 1\n",
        "print(\"Updated Purchases:\", customer_sales_record[\"purchases\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "6v6taqJ8yV5q"
      },
      "outputs": [],
      "source": [
        "sales_by_region = {\n",
        "    \"North\": 50000,\n",
        "    \"South\": 45000,\n",
        "    \"East\": 60000,\n",
        "    \"West\": 55000\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Sales by Region: 210000\n",
            "Region Names: ['North', 'South', 'East', 'West']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "## 1. calculate the total sales across all regions\n",
        "total_sales = sum(sales_by_region.values())\n",
        "print(\"Total Sales by Region:\", total_sales)\n",
        "\n",
        "## 2. get a list of all the region names (keys)\n",
        "\n",
        "region_names = list(sales_by_region.keys())\n",
        "print(\"Region Names:\", region_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXg3IMNMVFw9"
      },
      "source": [
        "#### You are given the string \"Data Analyst\" Write a Python program that counts how many times each character appears in the string and stores the results in a dictionary.\n",
        "\n",
        "Expected Output : `{'D': 1, 'a': 3, 't': 2, ' ': 1, 'A': 1, 'n': 1, 'l': 1, 'y': 1, 's': 1}`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "aCgJEa65VG25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'D': 1, 'a': 3, 't': 2, ' ': 1, 'A': 1, 'n': 1, 'l': 1, 'y': 1, 's': 1}\n"
          ]
        }
      ],
      "source": [
        "text = \"Data Analyst\"\n",
        "char_count = {}  \n",
        "\n",
        "for char in text:\n",
        "    if char in char_count:\n",
        "        char_count[char] += 1  \n",
        "    else:\n",
        "        char_count[char] =1\n",
        "\n",
        "print(char_count)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMsmgzAQuqyV"
      },
      "source": [
        "#### Write a function `clean_numeric_column(data_list`) that takes a list of mixed data types representing a database column\n",
        "1. Converts valid numbers (int, float, numeric strings) to float\n",
        "2. Replaces invalid values with None\n",
        "3. Returns a tuple: (cleaned_list, count_of_invalid_values)\n",
        "4. Handles edge cases like empty strings, \"N/A\", whitespace\n",
        "\n",
        "** Expected output **\n",
        "```\n",
        "Cleaned: [1.0, 2.5, None, None, 3.7, None, None, 0.0, 0.0]\n",
        "Invalids: 4\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "7YK_V2LturKJ"
      },
      "outputs": [],
      "source": [
        "data_list = [1, \"2.5\", \"invalid\", \"\", \"  3.7  \", None, \"N/A\", 0, \"0.0\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "0aUwn6DssbsY"
      },
      "outputs": [],
      "source": [
        "def clean_nemreic_column(data):\n",
        "    cleaned_data = []\n",
        "    for item in data_list:\n",
        "        if isinstance(item, str):\n",
        "            item = item.strip()  \n",
        "            if item.lower() in [\"\", \"n/a\", \"none\"]:  \n",
        "                cleaned_data.append(0.0)  \n",
        "            else:\n",
        "                try:\n",
        "                    cleaned_data.append(float(item))  \n",
        "                except ValueError:\n",
        "                    cleaned_data.append(0.0)  \n",
        "        elif isinstance(item, (int, float)):\n",
        "            cleaned_data.append(float(item))  \n",
        "        else:\n",
        "            cleaned_data.append(0.0)  \n",
        "    return cleaned_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWrHP_Qsl89B"
      },
      "source": [
        "#### Write a Python function `clean_column_names(column_list)` that:\n",
        "1. Takes a list of database column names (strings)\n",
        "2. Removes leading/trailing whitespace\n",
        "3. Converts to lowercase\n",
        "4. Replaces spaces and special characters with underscores\n",
        "5. Returns the cleaned list\n",
        "\n",
        "**Example input**: `[\" First Name \", \"Email@Address\", \"Phone-Number\", \" DATE_CREATED \"]`\n",
        "\n",
        "**Expected output:** *[\"first_name\", \"email_address\", \"phone_number\", \"date_created\"]*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "UNWDyZWQpJVP"
      },
      "outputs": [],
      "source": [
        "column_names = [\" First Name \", \"Email@Address\", \"Phone-Number\", \" DATE_CREATED \"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "1Yn7A0Wt-tZa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['first_name', 'email_address', 'phone_number', 'date_created']\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def clean_column_names(column_list):\n",
        "    cleaned = []\n",
        "    for col in column_list:\n",
        "        col = col.strip()                \n",
        "        col = col.lower()                 \n",
        "        col = re.sub(r'[^a-z0-9]+', '_', col)  \n",
        "        cleaned.append(col)\n",
        "    return cleaned\n",
        "\n",
        "\n",
        "columns = [\" First Name \", \"Email@Address\", \"Phone-Number\", \" DATE_CREATED \"]\n",
        "result = clean_column_names(columns)\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gGLKw6yooWv"
      },
      "source": [
        "Write a Python function `validate_email_list(email_list)` that:\n",
        "1. Takes a list of email strings\n",
        "2. Returns a dictionary with two keys: \"valid\" and \"invalid\"\n",
        "3. Basic email validation: contains exactly one \"@\" and ends with a domain (contains .)\n",
        "4. Uses loops and conditionals to categorize emails\n",
        "\n",
        "**Example Input:** [\"user@domain.com\", \"invalid.email\", \"test@\", \"@domain.com\", \"good@example.org\"]\n",
        "\n",
        "**Expected Output :** {'valid': ['user@domain.com', 'good@example.org'], 'invalid': ['invalid.email', 'test@', '@domain.com']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "JI-tkhrJl32D"
      },
      "outputs": [],
      "source": [
        "emails = [\"user@domain.com\", \"invalid.email\", \"test@\", \"@domain.com\", \"good@example.org\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "1Xn8De3x-5KW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'valid': ['user@domain.com', 'good@example.org'], 'invalid': ['invalid.email', 'test@', '@domain.com']}\n"
          ]
        }
      ],
      "source": [
        "def validate_email_list(email_list):\n",
        "    result = {\n",
        "        \"valid\": [],\n",
        "        \"invalid\": []\n",
        "    }\n",
        "\n",
        "    for email in email_list:\n",
        "        if email.count(\"@\") == 1:\n",
        "            local_part, domain_part = email.split(\"@\")\n",
        "            \n",
        "            if \".\" in domain_part and local_part != \"\" and domain_part != \"\":\n",
        "                result[\"valid\"].append(email)\n",
        "            else:\n",
        "                result[\"invalid\"].append(email)\n",
        "        else:\n",
        "            result[\"invalid\"].append(email)\n",
        "    \n",
        "    return result\n",
        "\n",
        "\n",
        "emails = [\"user@domain.com\", \"invalid.email\", \"test@\", \"@domain.com\", \"good@example.org\"]\n",
        "print(validate_email_list(emails))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2msoaO7nz2t"
      },
      "source": [
        "#### Given these customer ID list from different data sources, Write a function `analyze_customer_overlap(source_a, source_b)` that returns a **dictionary** containing:\n",
        "\n",
        "1. Total unique customers across all sources\n",
        "2. Customers present in all sources (common customers)\n",
        "3. Customers unique to each source\n",
        "\n",
        "\n",
        "**Expected Output**\n",
        "```\n",
        "All unique customers: 7 total\n",
        "Common customers: {1003, 1004, 1005}\n",
        "Unique to A: {1001, 1002}\n",
        "Unique to B: {1006, 1007}\n",
        "```\n",
        "\n",
        "ðŸ’¡: Use set() and operations like &, |, and - to compare customer lists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "je9-dn0Tn_gG"
      },
      "outputs": [],
      "source": [
        "customer_ids_source_a = [1001, 1002, 1003, 1004, 1005]\n",
        "customer_ids_source_b = [1003, 1004, 1005, 1006, 1007]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_customer_overlap(A, b):\n",
        "    all_customers = A + [x for x in A if x not in b]\n",
        "\n",
        "    common_customers = [x for x in A if x in b]\n",
        "\n",
        "    unique_to_a = [x for x in A if x not in b]\n",
        "\n",
        "    unique_to_b = [x for x in A if x not in b]\n",
        "\n",
        "    print(f\"All unique customers: {len(all_customers)} total\")\n",
        "    print(f\"Common customers: {common_customers}\")\n",
        "    print(f\"Unique to A: {unique_to_a}\")\n",
        "    print(f\"Unique to B: {unique_to_b}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All unique customers: 7 total\n",
            "Common customers: [1003, 1004, 1005]\n",
            "Unique to A: [1001, 1002]\n",
            "Unique to B: [1001, 1002]\n"
          ]
        }
      ],
      "source": [
        "analyze_customer_overlap(customer_ids_source_a, customer_ids_source_b)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXNOUrxVpnvI"
      },
      "source": [
        "Write a python script to\n",
        "1. count how many files are in each immediate parent directory (the last folder before the file name).\n",
        "2. Print the counts in the format:\n",
        "```\n",
        "raw: 2\n",
        "processed: 1\n",
        "logs: 1\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "gvAXXO75phrr"
      },
      "outputs": [],
      "source": [
        "filepaths = [\n",
        "    \"/data/raw/customers1.csv\",\n",
        "    \"/data/raw/customers2.csv\",\n",
        "    \"/data/raw/customers3.csv\",\n",
        "    \"/data/raw/customers4.csv\",\n",
        "    \"/data/raw/customers5.csv\",\n",
        "    \"/data/processed/orders1.parquet\",\n",
        "    \"/data/processed/orders2.parquet\",\n",
        "    \"/data/processed/orders3.parquet\",\n",
        "    \"/logs/20250101.log\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "-qZLsGlGsJmC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "raw: 5\n",
            "processed: 3\n",
            "logs: 1\n"
          ]
        }
      ],
      "source": [
        "parent_folders = []\n",
        "for path in filepaths:\n",
        "    parts = path.split(\"/\")\n",
        "    parent_folders.append(parts[-2])  \n",
        "\n",
        "folder_counts = {}\n",
        "for folder in parent_folders:\n",
        "    if folder not in folder_counts:\n",
        "        folder_counts[folder] = 1\n",
        "    else:\n",
        "        folder_counts[folder] += 1\n",
        "\n",
        "for folder in folder_counts:\n",
        "    print(f\"{folder}: {folder_counts[folder]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rsph0XySnhNz"
      },
      "source": [
        "#### You are given a dictionary pipeline_metadata that contains metadata for a data pipeline, including its name, schedule, sources, destinations, transformations, and run history.\n",
        "\n",
        "Write a script that:\n",
        "1. Prints the pipeline name and version using f-strings.\n",
        "2. Prints the schedule.\n",
        "3. Joins and prints the list of sources and destinations as comma-separated strings.\n",
        "4. Extracts and prints only the names of enabled transformations (those set to True) from the nested \"transformations\" dictionary.\n",
        "5. Calculates and prints the total successful records processed from run_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "l-WsytImnrHS"
      },
      "outputs": [],
      "source": [
        "pipeline_metadata = {\n",
        "    \"name\": \"customer_data_pipeline\",\n",
        "    \"version\": \"2.1.0\",\n",
        "    \"schedule\": \"daily\",\n",
        "    \"sources\": [\"mysql_db\", \"api_endpoint\", \"csv_files\"],\n",
        "    \"destinations\": [\"data_warehouse\", \"analytics_db\"],\n",
        "    \"transformations\": {\n",
        "        \"data_cleaning\": True,\n",
        "        \"deduplication\": True,\n",
        "        \"validation\": False,\n",
        "        \"enrichment\": True,\n",
        "        \"aggregation\": False\n",
        "    },\n",
        "    \"run_history\": [\n",
        "        {\"date\": \"2024-01-01\", \"status\": \"success\", \"records_processed\": 10000},\n",
        "        {\"date\": \"2024-01-02\", \"status\": \"failed\", \"records_processed\": 0},\n",
        "        {\"date\": \"2024-01-03\", \"status\": \"success\", \"records_processed\": 12000}\n",
        "    ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "SLwb4PeZJg0v"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pipeline Name: customer_data_pipeline, Version: 2.1.0\n",
            "Schedule: daily\n",
            "Sources: mysql_db, api_endpoint, csv_files\n",
            "Destinations: data_warehouse, analytics_db\n",
            "Enabled Transformations: data_cleaning, deduplication, enrichment\n",
            "Total Successful Records Processed: 22000\n"
          ]
        }
      ],
      "source": [
        "print(f\"Pipeline Name: {pipeline_metadata['name']}, Version: {pipeline_metadata['version']}\")\n",
        "\n",
        "print(f\"Schedule: {pipeline_metadata['schedule']}\")\n",
        "\n",
        "print(f\"Sources: {', '.join(pipeline_metadata['sources'])}\")\n",
        "print(f\"Destinations: {', '.join(pipeline_metadata['destinations'])}\")\n",
        "\n",
        "enabled_transformations = [name for name, enabled in pipeline_metadata[\"transformations\"].items() if enabled]\n",
        "print(f\"Enabled Transformations: {', '.join(enabled_transformations)}\")\n",
        "\n",
        "total_successful_records = sum(run[\"records_processed\"] for run in pipeline_metadata[\"run_history\"] if run[\"status\"] == \"success\")\n",
        "print(f\"Total Successful Records Processed: {total_successful_records}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf7-xUCOuAu-"
      },
      "source": [
        "#### Write a Python function `generate_date_list(start_date, end_date)` that:\n",
        "1. Accepts two strings in \"YYYY-MM-DD\" format\n",
        "2. Returns a list of all dates from start_date to end_date (inclusive), as strings\n",
        "3. Uses only the standard library (datetime, timedelta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZlEPwbMuLJc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "HsL5dC7xIhlK"
      },
      "outputs": [],
      "source": [
        "# dictionary to store company data\n",
        "\n",
        "\n",
        "company = {\n",
        "    \"employees\": {\n",
        "        \"Ali\": {\n",
        "            \"age\": 30,\n",
        "            \"department\": \"HR\",\n",
        "            \"skills\": [\"communication\", \"recruitment\"]},\n",
        "        \"Mohammed\": {\n",
        "            \"age\": 35,\n",
        "            \"department\": \"IT\",\n",
        "            \"skills\": [\"python\", \"networking\"]}\n",
        "    },\n",
        "    \"departments\": [\"HR\", \"IT\", \"Finance\"],\n",
        "    \"locations\": [\"Amman\", \"Dubai\"]\n",
        "}\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "ztOcDQ17XZnk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ali's skills ['communication', 'recruitment']\n",
            "Mohammed's skills ['python', 'networking', 'communication']\n",
            "Mohammed's department  Finance\n"
          ]
        }
      ],
      "source": [
        "# how to access the skills for Ali\n",
        "ali_skills = company[\"employees\"][\"Ali\"][\"skills\"]\n",
        "print(\"ali's skills\" ,ali_skills)\n",
        "\n",
        "# add communication skill for mohammad\n",
        "\n",
        "company[\"employees\"][\"Mohammed\"][\"skills\"].append(\"communication\")\n",
        "print(\"Mohammed's skills\",company[\"employees\"][\"Mohammed\"][\"skills\"])\n",
        "\n",
        "# change the department for mohammad to Finance\n",
        "\n",
        "company[\"employees\"][\"Mohammed\"][\"department\"] = \"Finance\"\n",
        "print(\"Mohammed's department \",company[\"employees\"][\"Mohammed\"][\"department\"])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4ngcNoxXePB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "RNMUKK9KcoMG",
        "fdYk9xTagcaN",
        "c98SRPCepJcv"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
